{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbhMAi9ldfkq",
        "outputId": "e007a5ac-05e9-47f4-a903-54a3be0005bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Libraries and VGG16 modules imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# 1. INITIAL SETUP & LIBRARIES\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import datetime\n",
        "import json\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ… Libraries and VGG16 modules imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. DATASET EXTRACTION\n",
        "dataset_zip_path = '/content/drive/MyDrive/dataset.zip'\n",
        "extract_folder = '/content/betel_dataset'\n",
        "\n",
        "if not os.path.exists(dataset_zip_path):\n",
        "    print(f\"âŒ Dataset not found at: {dataset_zip_path}\")\n",
        "else:\n",
        "    if os.path.exists(extract_folder):\n",
        "        shutil.rmtree(extract_folder)\n",
        "    os.makedirs(extract_folder, exist_ok=True)\n",
        "    print(\"ğŸ“¦ Extracting dataset...\")\n",
        "    with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_folder)\n",
        "    print(\"âœ… Dataset extracted successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i20Zcy13QcLE",
        "outputId": "d1ffe37a-69b7-4b6e-ed30-d1bcb87dd64f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ Extracting dataset...\n",
            "âœ… Dataset extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. DIRECTORY SPLITTING (70/15/15)\n",
        "base_path = '/content/betel_dataset'\n",
        "source_data_path = os.path.join(base_path, 'dataset')\n",
        "processed_data_root = os.path.join(base_path, 'commercial_classification')\n",
        "os.makedirs(processed_data_root, exist_ok=True)\n",
        "\n",
        "train_dir = os.path.join(processed_data_root, 'train')\n",
        "val_dir = os.path.join(processed_data_root, 'val')\n",
        "test_dir = os.path.join(processed_data_root, 'test')\n",
        "\n",
        "# Logic to create splits if they don't exist\n",
        "if not os.path.exists(train_dir):\n",
        "    import random\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for cls in os.listdir(source_data_path):\n",
        "            os.makedirs(os.path.join(processed_data_root, split, cls), exist_ok=True)\n",
        "\n",
        "    for cls in os.listdir(source_data_path):\n",
        "        cls_path = os.path.join(source_data_path, cls)\n",
        "        if os.path.isdir(cls_path):\n",
        "            images = [f for f in os.listdir(cls_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "            random.shuffle(images)\n",
        "            n = len(images)\n",
        "            train_idx, val_idx = int(n*0.7), int(n*0.85)\n",
        "\n",
        "            for i, img in enumerate(images):\n",
        "                src = os.path.join(cls_path, img)\n",
        "                if i < train_idx: dst = os.path.join(train_dir, cls, img)\n",
        "                elif i < val_idx: dst = os.path.join(val_dir, cls, img)\n",
        "                else: dst = os.path.join(test_dir, cls, img)\n",
        "                shutil.copy(src, dst)\n",
        "    print(\"âœ… Training, Validation, and Test splits created!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xthLM6oYQsdh",
        "outputId": "5567ae1d-d483-4fd7-d67b-8a7be382ccf3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Training, Validation, and Test splits created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. VGG16 DATA GENERATORS (With Heavy Augmentation)\n",
        "# Note: VGG16 preprocess_input handles mean subtraction; we do NOT use rescale=1./255.\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    brightness_range=[0.7, 1.3],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=True)\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
        "\n",
        "num_classes = len(train_generator.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_3HYFAnQ3RT",
        "outputId": "4760491c-3665-410d-c578-9ae5e5272af5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1131 images belonging to 4 classes.\n",
            "Found 242 images belonging to 4 classes.\n",
            "Found 245 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. BUILDING THE MODEL (FIXED: Added layers before summary)\n",
        "print(\"\\nğŸ—ï¸ Building VGG16 Model...\")\n",
        "# Load the base\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "vgg_base.trainable = False # Freeze base initially\n",
        "\n",
        "# Create the Sequential model and ADD layers\n",
        "model = models.Sequential()\n",
        "model.add(vgg_base)                 # Add base model first\n",
        "model.add(layers.Flatten())         # Convert 3D features to 1D\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))      # Regularization to prevent overfitting\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Now summary will show all parameters\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "J1rK8GdOQ_8t",
        "outputId": "e956aba8-d715-4964-81bc-29e654ad3f8a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ—ï¸ Building VGG16 Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚    \u001b[38;5;34m14,714,688\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚     \u001b[38;5;34m6,422,784\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              â”‚         \u001b[38;5;34m1,028\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,784</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,138,500\u001b[0m (80.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,138,500</span> (80.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,423,812\u001b[0m (24.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,423,812</span> (24.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a low learning rate for Phase 1 to protect the pre-trained base\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "save_dir = '/content/vgg16_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Properly formatted callback list to prevent syntax errors\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(save_dir, f'vgg16_best_{timestamp}.h5'),\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"âœ… Callbacks and compilation configured successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIeAjHmJRzvg",
        "outputId": "8472c100-332d-420a-9201-bde863da79b7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Callbacks and compilation configured successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸš€ TRAINING PHASE 1: Feature Extraction (Base Frozen)...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvIgURJgUfV6",
        "outputId": "f5411719-fcfb-4c55-ba50-ccb325505dc4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸš€ TRAINING PHASE 1: Feature Extraction (Base Frozen)...\n",
            "Epoch 1/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8465 - loss: 0.4253\n",
            "Epoch 1: val_accuracy improved from -inf to 0.84821, saving model to /content/vgg16_checkpoints/vgg16_best_20260102_163841.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 3s/step - accuracy: 0.8466 - loss: 0.4265 - val_accuracy: 0.8482 - val_loss: 0.5746\n",
            "Epoch 2/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8125 - loss: 0.4861\n",
            "Epoch 2: val_accuracy did not improve from 0.84821\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 404ms/step - accuracy: 0.8125 - loss: 0.4861 - val_accuracy: 0.8438 - val_loss: 0.5803\n",
            "Epoch 3/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8548 - loss: 0.4613\n",
            "Epoch 3: val_accuracy improved from 0.84821 to 0.87054, saving model to /content/vgg16_checkpoints/vgg16_best_20260102_163841.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3s/step - accuracy: 0.8549 - loss: 0.4604 - val_accuracy: 0.8705 - val_loss: 0.4913\n",
            "Epoch 4/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8750 - loss: 0.3821\n",
            "Epoch 4: val_accuracy did not improve from 0.87054\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 384ms/step - accuracy: 0.8750 - loss: 0.3821 - val_accuracy: 0.8661 - val_loss: 0.4947\n",
            "Epoch 5/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8536 - loss: 0.4634\n",
            "Epoch 5: val_accuracy did not improve from 0.87054\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3s/step - accuracy: 0.8535 - loss: 0.4630 - val_accuracy: 0.8036 - val_loss: 0.7998\n",
            "Epoch 6/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7188 - loss: 0.8958\n",
            "Epoch 6: val_accuracy did not improve from 0.87054\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 458ms/step - accuracy: 0.7188 - loss: 0.8958 - val_accuracy: 0.8214 - val_loss: 0.7709\n",
            "Epoch 7/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8490 - loss: 0.4650\n",
            "Epoch 7: val_accuracy did not improve from 0.87054\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3s/step - accuracy: 0.8491 - loss: 0.4645 - val_accuracy: 0.8393 - val_loss: 0.7047\n",
            "Epoch 8/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8750 - loss: 0.4885\n",
            "Epoch 8: val_accuracy did not improve from 0.87054\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 438ms/step - accuracy: 0.8750 - loss: 0.4885 - val_accuracy: 0.8393 - val_loss: 0.6741\n",
            "Epoch 9/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8568 - loss: 0.4024\n",
            "Epoch 9: val_accuracy did not improve from 0.87054\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3s/step - accuracy: 0.8570 - loss: 0.4021 - val_accuracy: 0.8482 - val_loss: 0.4599\n",
            "Epoch 10/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9375 - loss: 0.3179\n",
            "Epoch 10: val_accuracy did not improve from 0.87054\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 429ms/step - accuracy: 0.9375 - loss: 0.3179 - val_accuracy: 0.8482 - val_loss: 0.4563\n",
            "Epoch 11/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8664 - loss: 0.3892\n",
            "Epoch 11: val_accuracy did not improve from 0.87054\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3s/step - accuracy: 0.8663 - loss: 0.3894 - val_accuracy: 0.8616 - val_loss: 0.3627\n",
            "Epoch 12/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9688 - loss: 0.1125\n",
            "Epoch 12: val_accuracy did not improve from 0.87054\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 438ms/step - accuracy: 0.9688 - loss: 0.1125 - val_accuracy: 0.8616 - val_loss: 0.3695\n",
            "Epoch 13/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8773 - loss: 0.3180\n",
            "Epoch 13: val_accuracy improved from 0.87054 to 0.88393, saving model to /content/vgg16_checkpoints/vgg16_best_20260102_163841.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3s/step - accuracy: 0.8770 - loss: 0.3191 - val_accuracy: 0.8839 - val_loss: 0.3857\n",
            "Epoch 14/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8438 - loss: 0.3808\n",
            "Epoch 14: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 443ms/step - accuracy: 0.8438 - loss: 0.3808 - val_accuracy: 0.8839 - val_loss: 0.3960\n",
            "Epoch 15/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8819 - loss: 0.3495\n",
            "Epoch 15: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3s/step - accuracy: 0.8816 - loss: 0.3498 - val_accuracy: 0.8705 - val_loss: 0.4626\n",
            "Epoch 16/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8750 - loss: 0.1412\n",
            "Epoch 16: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 454ms/step - accuracy: 0.8750 - loss: 0.1412 - val_accuracy: 0.8616 - val_loss: 0.4765\n",
            "Epoch 17/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8738 - loss: 0.3705\n",
            "Epoch 17: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3s/step - accuracy: 0.8734 - loss: 0.3717 - val_accuracy: 0.8482 - val_loss: 0.5001\n",
            "Epoch 18/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9375 - loss: 0.1834\n",
            "Epoch 18: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 467ms/step - accuracy: 0.9375 - loss: 0.1834 - val_accuracy: 0.8527 - val_loss: 0.5036\n",
            "Epoch 19/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8638 - loss: 0.4035\n",
            "Epoch 19: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3s/step - accuracy: 0.8638 - loss: 0.4039 - val_accuracy: 0.8571 - val_loss: 0.4317\n",
            "Epoch 20/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8750 - loss: 0.3874\n",
            "Epoch 20: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 469ms/step - accuracy: 0.8750 - loss: 0.3874 - val_accuracy: 0.8571 - val_loss: 0.4371\n",
            "Epoch 21/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8382 - loss: 0.4178\n",
            "Epoch 21: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.8391 - loss: 0.4156 - val_accuracy: 0.8616 - val_loss: 0.4000\n",
            "Epoch 22/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7812 - loss: 0.4390\n",
            "Epoch 22: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 425ms/step - accuracy: 0.7812 - loss: 0.4390 - val_accuracy: 0.8571 - val_loss: 0.4147\n",
            "Epoch 23/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8652 - loss: 0.3746\n",
            "Epoch 23: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3s/step - accuracy: 0.8653 - loss: 0.3742 - val_accuracy: 0.8571 - val_loss: 0.5393\n",
            "Epoch 24/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9688 - loss: 0.1298\n",
            "Epoch 24: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 447ms/step - accuracy: 0.9688 - loss: 0.1298 - val_accuracy: 0.8571 - val_loss: 0.5341\n",
            "Epoch 25/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8944 - loss: 0.3232\n",
            "Epoch 25: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3s/step - accuracy: 0.8943 - loss: 0.3229 - val_accuracy: 0.8616 - val_loss: 0.4610\n",
            "Epoch 26/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7812 - loss: 0.6559\n",
            "Epoch 26: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 438ms/step - accuracy: 0.7812 - loss: 0.6559 - val_accuracy: 0.8616 - val_loss: 0.4583\n",
            "Epoch 27/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8654 - loss: 0.3450\n",
            "Epoch 27: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3s/step - accuracy: 0.8659 - loss: 0.3441 - val_accuracy: 0.8750 - val_loss: 0.3862\n",
            "Epoch 28/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8125 - loss: 0.3175\n",
            "Epoch 28: val_accuracy did not improve from 0.88393\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 447ms/step - accuracy: 0.8125 - loss: 0.3175 - val_accuracy: 0.8750 - val_loss: 0.3761\n",
            "Epoch 29/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8663 - loss: 0.3483\n",
            "Epoch 29: val_accuracy improved from 0.88393 to 0.89732, saving model to /content/vgg16_checkpoints/vgg16_best_20260102_163841.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3s/step - accuracy: 0.8663 - loss: 0.3485 - val_accuracy: 0.8973 - val_loss: 0.3426\n",
            "Epoch 30/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8438 - loss: 0.3215\n",
            "Epoch 30: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 455ms/step - accuracy: 0.8438 - loss: 0.3215 - val_accuracy: 0.8929 - val_loss: 0.3427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸš€ TRAINING PHASE 1: Feature Extraction (Base Frozen)...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tO7dPIzcuna",
        "outputId": "0519fbf2-70fc-4922-c4f6-be73e0beb027"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸš€ TRAINING PHASE 1: Feature Extraction (Base Frozen)...\n",
            "Epoch 1/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8778 - loss: 0.3281\n",
            "Epoch 1: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3s/step - accuracy: 0.8779 - loss: 0.3284 - val_accuracy: 0.8795 - val_loss: 0.3624\n",
            "Epoch 2/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8438 - loss: 0.5047\n",
            "Epoch 2: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 442ms/step - accuracy: 0.8438 - loss: 0.5047 - val_accuracy: 0.8795 - val_loss: 0.3669\n",
            "Epoch 3/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8898 - loss: 0.2857\n",
            "Epoch 3: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.8901 - loss: 0.2857 - val_accuracy: 0.8571 - val_loss: 0.4103\n",
            "Epoch 4/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9375 - loss: 0.1768\n",
            "Epoch 4: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 447ms/step - accuracy: 0.9375 - loss: 0.1768 - val_accuracy: 0.8571 - val_loss: 0.4056\n",
            "Epoch 5/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8932 - loss: 0.3216\n",
            "Epoch 5: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3s/step - accuracy: 0.8929 - loss: 0.3216 - val_accuracy: 0.8750 - val_loss: 0.3717\n",
            "Epoch 6/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8750 - loss: 0.4561\n",
            "Epoch 6: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 440ms/step - accuracy: 0.8750 - loss: 0.4561 - val_accuracy: 0.8795 - val_loss: 0.3676\n",
            "Epoch 7/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8886 - loss: 0.2760\n",
            "Epoch 7: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3s/step - accuracy: 0.8886 - loss: 0.2762 - val_accuracy: 0.8929 - val_loss: 0.3264\n",
            "Epoch 8/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9375 - loss: 0.3593\n",
            "Epoch 8: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 449ms/step - accuracy: 0.9375 - loss: 0.3593 - val_accuracy: 0.8973 - val_loss: 0.3317\n",
            "Epoch 9/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8897 - loss: 0.3308\n",
            "Epoch 9: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3s/step - accuracy: 0.8895 - loss: 0.3303 - val_accuracy: 0.8750 - val_loss: 0.3778\n",
            "Epoch 10/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9062 - loss: 0.3210\n",
            "Epoch 10: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 451ms/step - accuracy: 0.9062 - loss: 0.3210 - val_accuracy: 0.8750 - val_loss: 0.3784\n",
            "Epoch 11/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8948 - loss: 0.3079\n",
            "Epoch 11: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3s/step - accuracy: 0.8945 - loss: 0.3090 - val_accuracy: 0.8750 - val_loss: 0.3776\n",
            "Epoch 12/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8750 - loss: 0.3027\n",
            "Epoch 12: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 449ms/step - accuracy: 0.8750 - loss: 0.3027 - val_accuracy: 0.8750 - val_loss: 0.3779\n",
            "Epoch 13/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9017 - loss: 0.2932\n",
            "Epoch 13: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3s/step - accuracy: 0.9014 - loss: 0.2935 - val_accuracy: 0.8929 - val_loss: 0.3245\n",
            "Epoch 14/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9688 - loss: 0.1267\n",
            "Epoch 14: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 444ms/step - accuracy: 0.9688 - loss: 0.1267 - val_accuracy: 0.8929 - val_loss: 0.3297\n",
            "Epoch 15/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8772 - loss: 0.3068\n",
            "Epoch 15: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3s/step - accuracy: 0.8773 - loss: 0.3065 - val_accuracy: 0.8527 - val_loss: 0.4488\n",
            "Epoch 16/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9375 - loss: 0.1755\n",
            "Epoch 16: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 445ms/step - accuracy: 0.9375 - loss: 0.1755 - val_accuracy: 0.8527 - val_loss: 0.4467\n",
            "Epoch 17/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8917 - loss: 0.2893\n",
            "Epoch 17: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3s/step - accuracy: 0.8918 - loss: 0.2897 - val_accuracy: 0.8571 - val_loss: 0.3785\n",
            "Epoch 18/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9375 - loss: 0.1240\n",
            "Epoch 18: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 462ms/step - accuracy: 0.9375 - loss: 0.1240 - val_accuracy: 0.8571 - val_loss: 0.3832\n",
            "Epoch 19/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8709 - loss: 0.3400\n",
            "Epoch 19: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.8711 - loss: 0.3400 - val_accuracy: 0.8661 - val_loss: 0.3727\n",
            "Epoch 20/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9688 - loss: 0.0951\n",
            "Epoch 20: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 446ms/step - accuracy: 0.9688 - loss: 0.0951 - val_accuracy: 0.8661 - val_loss: 0.3701\n",
            "Epoch 21/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8730 - loss: 0.3116\n",
            "Epoch 21: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 3s/step - accuracy: 0.8734 - loss: 0.3109 - val_accuracy: 0.8616 - val_loss: 0.4499\n",
            "Epoch 22/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7812 - loss: 0.4063\n",
            "Epoch 22: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 442ms/step - accuracy: 0.7812 - loss: 0.4063 - val_accuracy: 0.8616 - val_loss: 0.4671\n",
            "Epoch 23/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8764 - loss: 0.3502\n",
            "Epoch 23: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3s/step - accuracy: 0.8763 - loss: 0.3512 - val_accuracy: 0.8661 - val_loss: 0.4739\n",
            "Epoch 24/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9375 - loss: 0.2486\n",
            "Epoch 24: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 451ms/step - accuracy: 0.9375 - loss: 0.2486 - val_accuracy: 0.8661 - val_loss: 0.4705\n",
            "Epoch 25/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8807 - loss: 0.2759\n",
            "Epoch 25: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3s/step - accuracy: 0.8809 - loss: 0.2762 - val_accuracy: 0.8705 - val_loss: 0.4547\n",
            "Epoch 26/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0647\n",
            "Epoch 26: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0647 - val_accuracy: 0.8705 - val_loss: 0.4566\n",
            "Epoch 27/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9010 - loss: 0.2590\n",
            "Epoch 27: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3s/step - accuracy: 0.9009 - loss: 0.2593 - val_accuracy: 0.8482 - val_loss: 0.5061\n",
            "Epoch 28/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8438 - loss: 0.5190\n",
            "Epoch 28: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 453ms/step - accuracy: 0.8438 - loss: 0.5190 - val_accuracy: 0.8438 - val_loss: 0.5274\n",
            "Epoch 29/30\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8852 - loss: 0.2935\n",
            "Epoch 29: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3s/step - accuracy: 0.8853 - loss: 0.2936 - val_accuracy: 0.8750 - val_loss: 0.4269\n",
            "Epoch 30/30\n",
            "\u001b[1m 1/35\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9375 - loss: 0.2856\n",
            "Epoch 30: val_accuracy did not improve from 0.89732\n",
            "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 454ms/step - accuracy: 0.9375 - loss: 0.2856 - val_accuracy: 0.8750 - val_loss: 0.4271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nğŸ¯ Final Test Set Performance Evaluation:\")\n",
        "# Load the best weights saved by the checkpoint before evaluating\n",
        "model.load_weights(os.path.join(save_dir, f'vgg16_best_{timestamp}.h5'))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"\\nâœ… FINAL TEST ACCURACY: {test_acc*100:.2f}%\")\n",
        "print(f\"âœ… FINAL TEST LOSS: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W32i04OqkBDF",
        "outputId": "f9dcccf0-1309-4582-9521-54d037b30b6b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ¯ Final Test Set Performance Evaluation:\n",
            "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9260 - loss: 0.1690\n",
            "\n",
            "âœ… FINAL TEST ACCURACY: 86.53%\n",
            "âœ… FINAL TEST LOSS: 0.3396\n"
          ]
        }
      ]
    }
  ]
}