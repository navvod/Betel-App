{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bJiCKKJr2BP",
        "outputId": "282a0518-021a-4394-c091-994bb27a2c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries ready!\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Imports and Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import statsmodels.api as sm\n",
        "import joblib\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Create models folder\n",
        "os.makedirs('models_ensemble_tuned', exist_ok=True)\n",
        "\n",
        "print(\"All libraries ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load and Initial Clean\n",
        "df = pd.read_csv('BetelPrice.csv')\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')\n",
        "df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# Remove garbage columns\n",
        "df = df.drop(columns=['Unnamed: 6', ' '], errors='ignore')\n",
        "\n",
        "# Basic cleaning\n",
        "df = df.dropna(subset=['Price'])\n",
        "df = df[df['Price'] > 0].reset_index(drop=True)\n",
        "\n",
        "print(f\"Total rows after initial clean: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh9KPssfsndk",
        "outputId": "cd299c66-b139-45c0-b179-c16a60237e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows after initial clean: 9429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Outlier Removal per Commercial Type (IQR Method)\n",
        "commercial_types = ['Peedunu', 'Keti', 'Kanda', 'Korikan']\n",
        "df_clean = pd.DataFrame()\n",
        "\n",
        "for ctype in commercial_types:\n",
        "    print(f\"\\n--- {ctype} ---\")\n",
        "    subset = df[df['Commercial Type'] == ctype].copy()\n",
        "    print(f\"Original rows: {len(subset)} | Price range: {subset['Price'].min()} - {subset['Price'].max()}\")\n",
        "\n",
        "    # IQR outlier detection\n",
        "    Q1 = subset['Price'].quantile(0.25)\n",
        "    Q3 = subset['Price'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "\n",
        "    before = len(subset)\n",
        "    subset = subset[(subset['Price'] >= lower) & (subset['Price'] <= upper)]\n",
        "    after = len(subset)\n",
        "\n",
        "    print(f\"After outlier removal: {after} rows (removed {before - after})\")\n",
        "    print(f\"New price range: {subset['Price'].min()} - {subset['Price'].max()}\")\n",
        "\n",
        "    df_clean = pd.concat([df_clean, subset], ignore_index=True)\n",
        "\n",
        "df = df_clean\n",
        "print(f\"\\nFinal total rows after outlier removal across all types: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pzI1FP_st6l",
        "outputId": "1570085a-27ca-47cf-daef-008692f7ef22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Peedunu ---\n",
            "Original rows: 3776 | Price range: 200 - 30000\n",
            "After outlier removal: 3590 rows (removed 186)\n",
            "New price range: 200 - 12000\n",
            "\n",
            "--- Keti ---\n",
            "Original rows: 1888 | Price range: 50 - 10000\n",
            "After outlier removal: 1812 rows (removed 76)\n",
            "New price range: 50 - 5000\n",
            "\n",
            "--- Kanda ---\n",
            "Original rows: 1888 | Price range: 250 - 20000\n",
            "After outlier removal: 1785 rows (removed 103)\n",
            "New price range: 250 - 11000\n",
            "\n",
            "--- Korikan ---\n",
            "Original rows: 1877 | Price range: 20 - 4000\n",
            "After outlier removal: 1757 rows (removed 120)\n",
            "New price range: 20 - 1800\n",
            "\n",
            "Final total rows after outlier removal across all types: 8944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Training Loop with Tuned LSTM + SARIMA Ensemble\n",
        "time_steps = 60\n",
        "results = {}\n",
        "\n",
        "print(\"\\nStarting fine-tuned training with LSTM + SARIMA ensemble...\\n\")\n",
        "\n",
        "for ctype in commercial_types:\n",
        "    print(\"=\"*70)\n",
        "    print(f\"FINE-TUNING ENSEMBLE MODEL FOR: {ctype.upper()}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    subset = df[df['Commercial Type'] == ctype].copy()\n",
        "    print(f\"Rows: {len(subset)}\")\n",
        "\n",
        "    if len(subset) < 300:\n",
        "        print(f\"Skipping {ctype} - insufficient data after cleaning.\\n\")\n",
        "        continue\n",
        "\n",
        "    # Add cyclical date features\n",
        "    subset['Month_sin'] = np.sin(2 * np.pi * subset['Date'].dt.month / 12)\n",
        "    subset['Month_cos'] = np.cos(2 * np.pi * subset['Date'].dt.month / 12)\n",
        "    subset['DayOfYear_sin'] = np.sin(2 * np.pi * subset['Date'].dt.dayofyear / 365.25)\n",
        "    subset['DayOfYear_cos'] = np.cos(2 * np.pi * subset['Date'].dt.dayofyear / 365.25)\n",
        "\n",
        "    # Encode categoricals\n",
        "    cat_cols = ['District', 'Market Type', 'Quality Grade']\n",
        "    subset_encoded = pd.get_dummies(subset, columns=cat_cols, dtype=float, drop_first=True)\n",
        "\n",
        "    # Features\n",
        "    feature_cols = ['Price'] + [col for col in subset_encoded.columns if col not in ['Date', 'Price', 'Commercial Type']]\n",
        "    data = subset_encoded[feature_cols].values.astype(np.float32)\n",
        "\n",
        "    # Log + scale Price\n",
        "    data_log = data.copy()\n",
        "    data_log[:, 0] = np.log(data[:, 0])\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = data_log.copy()\n",
        "    data_scaled[:, 0] = scaler.fit_transform(data_log[:, [0]]).flatten()\n",
        "\n",
        "    # Create sequences for LSTM\n",
        "    X, y = [], []\n",
        "    for i in range(len(data_scaled) - time_steps):\n",
        "        X.append(data_scaled[i:i + time_steps])\n",
        "        y.append(data_scaled[i + time_steps, 0])\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    if len(X) < 50:\n",
        "        print(f\"Not enough sequences for {ctype}.\\n\")\n",
        "        continue\n",
        "\n",
        "    # 70/15/15 split: train/val/test\n",
        "    train_idx = int(0.7 * len(X))\n",
        "    val_idx = int(0.85 * len(X))\n",
        "    X_train, X_val, X_test = X[:train_idx], X[train_idx:val_idx], X[val_idx:]\n",
        "    y_train, y_val, y_test = y[:train_idx], y[train_idx:val_idx], y[val_idx:]\n",
        "\n",
        "    # === Tuned LSTM Model ===\n",
        "    lstm_model = Sequential()\n",
        "    lstm_model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(time_steps, X.shape[2])))\n",
        "    lstm_model.add(Dropout(0.2))\n",
        "    lstm_model.add(Bidirectional(LSTM(128)))\n",
        "    lstm_model.add(Dropout(0.2))\n",
        "    lstm_model.add(Dense(64, activation='relu'))\n",
        "    lstm_model.add(Dense(1))\n",
        "\n",
        "    lstm_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='mse')\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, verbose=0)\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6, verbose=0)\n",
        "\n",
        "    lstm_model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_val, y_val),\n",
        "                   callbacks=[early_stop, lr_scheduler], verbose=0)\n",
        "\n",
        "    # LSTM predictions on val and test\n",
        "    lstm_val_scaled = lstm_model.predict(X_val, verbose=0)\n",
        "    lstm_test_scaled = lstm_model.predict(X_test, verbose=0)\n",
        "    lstm_val = np.exp(scaler.inverse_transform(lstm_val_scaled))\n",
        "    lstm_test = np.exp(scaler.inverse_transform(lstm_test_scaled))\n",
        "\n",
        "    # === SARIMA Model ===\n",
        "    price_series = subset['Price'].values\n",
        "    try:\n",
        "        sarima_model = sm.tsa.SARIMAX(price_series, order=(1,1,1), seasonal_order=(1,1,1,12))\n",
        "        sarima_fit = sarima_model.fit(disp=False)\n",
        "        sarima_val = sarima_fit.forecast(steps=len(X_val))\n",
        "        sarima_test = sarima_fit.forecast(steps=len(X_test))\n",
        "    except:\n",
        "        print(f\"SARIMA failed for {ctype}. Using LSTM only.\")\n",
        "        sarima_val = np.full_like(lstm_val, np.mean(price_series[-100:]))\n",
        "        sarima_test = np.full_like(lstm_test, np.mean(price_series[-100:]))\n",
        "\n",
        "    # Val truths for weight tuning\n",
        "    y_val_true = np.exp(scaler.inverse_transform(y_val.reshape(-1, 1))).flatten()\n",
        "\n",
        "    # Tune ensemble weights on validation set\n",
        "    weights = np.linspace(0, 1, 11)  # 0 to 1 in 0.1 steps\n",
        "    best_weight = 0.5\n",
        "    best_mape = float('inf')\n",
        "    for w in weights:\n",
        "        val_ensemble = w * lstm_val.flatten() + (1 - w) * sarima_val\n",
        "        val_mape = np.mean(np.abs((y_val_true - val_ensemble) / y_val_true)) * 100\n",
        "        if val_mape < best_mape:\n",
        "            best_mape = val_mape\n",
        "            best_weight = w\n",
        "\n",
        "    print(f\"Best ensemble weight (LSTM): {best_weight:.2f} (tuned on validation)\")\n",
        "\n",
        "    # Apply best weight to test\n",
        "    ensemble_test = best_weight * lstm_test.flatten() + (1 - best_weight) * sarima_test\n",
        "\n",
        "    y_test_true = np.exp(scaler.inverse_transform(y_test.reshape(-1, 1))).flatten()\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_true, ensemble_test))\n",
        "    mae = mean_absolute_error(y_test_true, ensemble_test)\n",
        "    mape = np.mean(np.abs((y_test_true - ensemble_test) / y_test_true)) * 100\n",
        "\n",
        "    print(f\"ENSEMBLE RESULTS → RMSE: {rmse:.0f} | MAE: {mae:.0f} | MAPE: {mape:.1f}%\\n\")\n",
        "\n",
        "    results[ctype] = {'RMSE': rmse, 'MAE': mae, 'MAPE': mape}\n",
        "\n",
        "    # Save models\n",
        "    lstm_model.save(f'models_ensemble_tuned/lstm_{ctype}.h5')\n",
        "    joblib.dump(scaler, f'models_ensemble_tuned/scaler_{ctype}.pkl')\n",
        "    joblib.dump(sarima_fit, f'models_ensemble_tuned/sarima_{ctype}.pkl')\n",
        "    joblib.dump(best_weight, f'models_ensemble_tuned/weight_{ctype}.pkl')\n",
        "    print(f\"Models saved for {ctype}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQk9xpdSsvUm",
        "outputId": "fe0fcc5d-6b17-4031-8e16-0d780e2631fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting fine-tuned training with LSTM + SARIMA ensemble...\n",
            "\n",
            "======================================================================\n",
            "FINE-TUNING ENSEMBLE MODEL FOR: PEEDUNU\n",
            "======================================================================\n",
            "Rows: 3590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ensemble weight (LSTM): 1.00 (tuned on validation)\n",
            "ENSEMBLE RESULTS → RMSE: 2637 | MAE: 2111 | MAPE: 33.0%\n",
            "\n",
            "Models saved for Peedunu\n",
            "\n",
            "======================================================================\n",
            "FINE-TUNING ENSEMBLE MODEL FOR: KETI\n",
            "======================================================================\n",
            "Rows: 1812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ensemble weight (LSTM): 1.00 (tuned on validation)\n",
            "ENSEMBLE RESULTS → RMSE: 970 | MAE: 745 | MAPE: 31.6%\n",
            "\n",
            "Models saved for Keti\n",
            "\n",
            "======================================================================\n",
            "FINE-TUNING ENSEMBLE MODEL FOR: KANDA\n",
            "======================================================================\n",
            "Rows: 1785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ensemble weight (LSTM): 1.00 (tuned on validation)\n",
            "ENSEMBLE RESULTS → RMSE: 2325 | MAE: 1861 | MAPE: 25.6%\n",
            "\n",
            "Models saved for Kanda\n",
            "\n",
            "======================================================================\n",
            "FINE-TUNING ENSEMBLE MODEL FOR: KORIKAN\n",
            "======================================================================\n",
            "Rows: 1757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ensemble weight (LSTM): 1.00 (tuned on validation)\n",
            "ENSEMBLE RESULTS → RMSE: 331 | MAE: 243 | MAPE: 44.2%\n",
            "\n",
            "Models saved for Korikan\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Final Summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL TUNED ENSEMBLE PERFORMANCE SUMMARY (After Outlier Removal)\")\n",
        "print(\"=\"*80)\n",
        "for ctype in commercial_types:\n",
        "    if ctype in results:\n",
        "        m = results[ctype]\n",
        "        print(f\"{ctype:9} → MAPE: {m['MAPE']:5.1f}%  |  MAE: {m['MAE']:7.0f}  |  RMSE: {m['RMSE']:7.0f}\")\n",
        "    else:\n",
        "        print(f\"{ctype:9} → Skipped\")\n",
        "print(\"=\"*80)\n",
        "print(\"Improvement expected over previous version!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OGcT3kOt63c",
        "outputId": "fed9753d-219e-4c91-a749-a5f3bc080294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL TUNED ENSEMBLE PERFORMANCE SUMMARY (After Outlier Removal)\n",
            "================================================================================\n",
            "Peedunu   → MAPE:  33.0%  |  MAE:    2111  |  RMSE:    2637\n",
            "Keti      → MAPE:  31.6%  |  MAE:     745  |  RMSE:     970\n",
            "Kanda     → MAPE:  25.6%  |  MAE:    1861  |  RMSE:    2325\n",
            "Korikan   → MAPE:  44.2%  |  MAE:     243  |  RMSE:     331\n",
            "================================================================================\n",
            "Improvement expected over previous version!\n"
          ]
        }
      ]
    }
  ]
}