{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ6BxJyZaDge",
        "outputId": "0c85e516-4a2a-4ee1-bf81-074366f354b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries ready!\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Imports and Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import statsmodels.api as sm\n",
        "import joblib\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Create models folder\n",
        "os.makedirs('models_ensemble', exist_ok=True)\n",
        "\n",
        "print(\"All libraries ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load and Initial Clean\n",
        "df = pd.read_csv('BetelPrice.csv')\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')\n",
        "df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# Remove garbage columns\n",
        "df = df.drop(columns=['Unnamed: 6', ' '], errors='ignore')\n",
        "\n",
        "# Basic cleaning\n",
        "df = df.dropna(subset=['Price'])\n",
        "df = df[df['Price'] > 0].reset_index(drop=True)\n",
        "\n",
        "print(f\"Total rows after initial clean: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDD3Kf4uaQoG",
        "outputId": "f04c8cfa-0a17-4da8-dd34-323d8895aa37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows after initial clean: 9429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Outlier Removal per Commercial Type (IQR Method)\n",
        "commercial_types = ['Peedunu', 'Keti', 'Kanda', 'Korikan']\n",
        "df_clean = pd.DataFrame()\n",
        "\n",
        "for ctype in commercial_types:\n",
        "    print(f\"\\n--- {ctype} ---\")\n",
        "    subset = df[df['Commercial Type'] == ctype].copy()\n",
        "    print(f\"Original rows: {len(subset)} | Price range: {subset['Price'].min()} - {subset['Price'].max()}\")\n",
        "\n",
        "    # IQR outlier detection\n",
        "    Q1 = subset['Price'].quantile(0.25)\n",
        "    Q3 = subset['Price'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "\n",
        "    before = len(subset)\n",
        "    subset = subset[(subset['Price'] >= lower) & (subset['Price'] <= upper)]\n",
        "    after = len(subset)\n",
        "\n",
        "    print(f\"After outlier removal: {after} rows (removed {before - after})\")\n",
        "    print(f\"New price range: {subset['Price'].min()} - {subset['Price'].max()}\")\n",
        "\n",
        "    df_clean = pd.concat([df_clean, subset], ignore_index=True)\n",
        "\n",
        "df = df_clean\n",
        "print(f\"\\nFinal total rows after outlier removal across all types: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htHjPRe4aVMb",
        "outputId": "30901165-11d9-47e9-ad5e-ffa08ee004f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Peedunu ---\n",
            "Original rows: 3776 | Price range: 200 - 30000\n",
            "After outlier removal: 3590 rows (removed 186)\n",
            "New price range: 200 - 12000\n",
            "\n",
            "--- Keti ---\n",
            "Original rows: 1888 | Price range: 50 - 10000\n",
            "After outlier removal: 1812 rows (removed 76)\n",
            "New price range: 50 - 5000\n",
            "\n",
            "--- Kanda ---\n",
            "Original rows: 1888 | Price range: 250 - 20000\n",
            "After outlier removal: 1785 rows (removed 103)\n",
            "New price range: 250 - 11000\n",
            "\n",
            "--- Korikan ---\n",
            "Original rows: 1877 | Price range: 20 - 4000\n",
            "After outlier removal: 1757 rows (removed 120)\n",
            "New price range: 20 - 1800\n",
            "\n",
            "Final total rows after outlier removal across all types: 8944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Training Loop with LSTM + SARIMA Ensemble\n",
        "time_steps = 60\n",
        "results = {}\n",
        "\n",
        "print(\"\\nStarting training with LSTM + SARIMA ensemble...\\n\")\n",
        "\n",
        "for ctype in commercial_types:\n",
        "    print(\"=\"*70)\n",
        "    print(f\"TRAINING ENSEMBLE MODEL FOR: {ctype.upper()}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    subset = df[df['Commercial Type'] == ctype].copy()\n",
        "    print(f\"Rows: {len(subset)}\")\n",
        "\n",
        "    if len(subset) < 300:\n",
        "        print(f\"Skipping {ctype} - insufficient data after cleaning.\\n\")\n",
        "        continue\n",
        "\n",
        "    # Add cyclical date features\n",
        "    subset['Month_sin'] = np.sin(2 * np.pi * subset['Date'].dt.month / 12)\n",
        "    subset['Month_cos'] = np.cos(2 * np.pi * subset['Date'].dt.month / 12)\n",
        "    subset['DayOfYear_sin'] = np.sin(2 * np.pi * subset['Date'].dt.dayofyear / 365.25)\n",
        "    subset['DayOfYear_cos'] = np.cos(2 * np.pi * subset['Date'].dt.dayofyear / 365.25)\n",
        "\n",
        "    # Encode categoricals\n",
        "    cat_cols = ['District', 'Market Type', 'Quality Grade']\n",
        "    subset_encoded = pd.get_dummies(subset, columns=cat_cols, dtype=float, drop_first=True)\n",
        "\n",
        "    # Features\n",
        "    feature_cols = ['Price'] + [col for col in subset_encoded.columns if col not in ['Date', 'Price', 'Commercial Type']]\n",
        "    data = subset_encoded[feature_cols].values.astype(np.float32)\n",
        "\n",
        "    # Log + scale Price\n",
        "    data_log = data.copy()\n",
        "    data_log[:, 0] = np.log(data[:, 0])\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = data_log.copy()\n",
        "    data_scaled[:, 0] = scaler.fit_transform(data_log[:, [0]]).flatten()\n",
        "\n",
        "    # Create sequences for LSTM\n",
        "    X, y = [], []\n",
        "    for i in range(len(data_scaled) - time_steps):\n",
        "        X.append(data_scaled[i:i + time_steps])\n",
        "        y.append(data_scaled[i + time_steps, 0])\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    if len(X) < 50:\n",
        "        print(f\"Not enough sequences for {ctype}.\\n\")\n",
        "        continue\n",
        "\n",
        "    split_idx = int(0.8 * len(X))\n",
        "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "    # === LSTM Model ===\n",
        "    lstm_model = Sequential()\n",
        "    lstm_model.add(LSTM(64, return_sequences=True, input_shape=(time_steps, X.shape[2])))\n",
        "    lstm_model.add(Dropout(0.3))\n",
        "    lstm_model.add(LSTM(64))\n",
        "    lstm_model.add(Dropout(0.3))\n",
        "    lstm_model.add(Dense(32, activation='relu'))\n",
        "    lstm_model.add(Dense(1))\n",
        "\n",
        "    lstm_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=0)\n",
        "\n",
        "    lstm_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.1,\n",
        "                   callbacks=[early_stop], verbose=0)\n",
        "\n",
        "    # LSTM predictions\n",
        "    lstm_pred_scaled = lstm_model.predict(X_test, verbose=0)\n",
        "    lstm_pred = np.exp(scaler.inverse_transform(lstm_pred_scaled))\n",
        "\n",
        "    # === SARIMA Model ===\n",
        "    price_series = subset['Price'].values  # Use original cleaned prices\n",
        "    try:\n",
        "        sarima_model = sm.tsa.SARIMAX(price_series, order=(1,1,1), seasonal_order=(1,1,1,12))\n",
        "        sarima_fit = sarima_model.fit(disp=False)\n",
        "        sarima_pred = sarima_fit.forecast(steps=len(X_test))\n",
        "    except:\n",
        "        print(f\"SARIMA failed for {ctype}. Using LSTM only.\")\n",
        "        sarima_pred = np.full_like(lstm_pred, np.mean(price_series[-100:]))  # fallback\n",
        "\n",
        "    # === Ensemble: Simple Average ===\n",
        "    ensemble_pred = 0.5 * lstm_pred.flatten() + 0.5 * sarima_pred\n",
        "\n",
        "    y_true = np.exp(scaler.inverse_transform(y_test.reshape(-1, 1))).flatten()\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, ensemble_pred))\n",
        "    mae = mean_absolute_error(y_true, ensemble_pred)\n",
        "    mape = np.mean(np.abs((y_true - ensemble_pred) / y_true)) * 100\n",
        "\n",
        "    print(f\"ENSEMBLE RESULTS → RMSE: {rmse:.0f} | MAE: {mae:.0f} | MAPE: {mape:.1f}%\\n\")\n",
        "\n",
        "    results[ctype] = {'RMSE': rmse, 'MAE': mae, 'MAPE': mape}\n",
        "\n",
        "    # Save models\n",
        "    lstm_model.save(f'models_ensemble/lstm_{ctype}.h5')\n",
        "    joblib.dump(scaler, f'models_ensemble/scaler_{ctype}.pkl')\n",
        "    joblib.dump(sarima_fit, f'models_ensemble/sarima_{ctype}.pkl')\n",
        "    print(f\"Models saved for {ctype}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptDKcKAoaa2F",
        "outputId": "dd71c2bb-df04-4c8d-8925-8d7a541fad0f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training with LSTM + SARIMA ensemble...\n",
            "\n",
            "======================================================================\n",
            "TRAINING ENSEMBLE MODEL FOR: PEEDUNU\n",
            "======================================================================\n",
            "Rows: 3590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENSEMBLE RESULTS → RMSE: 2574 | MAE: 2065 | MAPE: 36.7%\n",
            "\n",
            "Models saved for Peedunu\n",
            "\n",
            "======================================================================\n",
            "TRAINING ENSEMBLE MODEL FOR: KETI\n",
            "======================================================================\n",
            "Rows: 1812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENSEMBLE RESULTS → RMSE: 1118 | MAE: 911 | MAPE: 43.4%\n",
            "\n",
            "Models saved for Keti\n",
            "\n",
            "======================================================================\n",
            "TRAINING ENSEMBLE MODEL FOR: KANDA\n",
            "======================================================================\n",
            "Rows: 1785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENSEMBLE RESULTS → RMSE: 1894 | MAE: 1513 | MAPE: 28.2%\n",
            "\n",
            "Models saved for Kanda\n",
            "\n",
            "======================================================================\n",
            "TRAINING ENSEMBLE MODEL FOR: KORIKAN\n",
            "======================================================================\n",
            "Rows: 1757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENSEMBLE RESULTS → RMSE: 338 | MAE: 281 | MAPE: 79.3%\n",
            "\n",
            "Models saved for Korikan\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Final Summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL ENSEMBLE PERFORMANCE SUMMARY (After Outlier Removal)\")\n",
        "print(\"=\"*80)\n",
        "for ctype in commercial_types:\n",
        "    if ctype in results:\n",
        "        m = results[ctype]\n",
        "        print(f\"{ctype:9} → MAPE: {m['MAPE']:5.1f}%  |  MAE: {m['MAE']:7.0f}  |  RMSE: {m['RMSE']:7.0f}\")\n",
        "    else:\n",
        "        print(f\"{ctype:9} → Skipped\")\n",
        "print(\"=\"*80)\n",
        "print(\"Improvement expected over previous version!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygg6UwcKbiWI",
        "outputId": "a2e319f5-9313-4965-e806-d5f5f8647a6c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL ENSEMBLE PERFORMANCE SUMMARY (After Outlier Removal)\n",
            "================================================================================\n",
            "Peedunu   → MAPE:  36.7%  |  MAE:    2065  |  RMSE:    2574\n",
            "Keti      → MAPE:  43.4%  |  MAE:     911  |  RMSE:    1118\n",
            "Kanda     → MAPE:  28.2%  |  MAE:    1513  |  RMSE:    1894\n",
            "Korikan   → MAPE:  79.3%  |  MAE:     281  |  RMSE:     338\n",
            "================================================================================\n",
            "Improvement expected over previous version!\n"
          ]
        }
      ]
    }
  ]
}